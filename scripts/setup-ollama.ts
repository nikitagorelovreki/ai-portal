import { OllamaClient } from '../src/llm/ollama-client';
import { config } from 'dotenv';

config();

async function main() {
  console.log('ğŸ”§ Ollama Setup and Test\n');

  const ollama = new OllamaClient();

  // Test connection
  console.log('ğŸ” Testing Ollama connection...');
  const isConnected = await ollama.testConnection();
  
  if (!isConnected) {
    console.log('âŒ Ollama is not running or not accessible');
    console.log('\nğŸ“‹ Setup Instructions:');
    console.log('1. Install Ollama: https://ollama.ai/download');
    console.log('2. Start Ollama: ollama serve');
    console.log('3. Pull a model: ollama pull llama2');
    console.log('4. Run this test again');
    return;
  }

  console.log('âœ… Ollama is running');

  // Get available models
  console.log('\nğŸ“š Checking available models...');
  const models = await ollama.getAvailableModels();
  
  if (models.length === 0) {
    console.log('âŒ No models found');
    console.log('\nğŸ“‹ To install a model, run:');
    console.log('   ollama pull llama2');
    console.log('   ollama pull mistral');
    console.log('   ollama pull codellama');
    return;
  }

  console.log('âœ… Available models:');
  models.forEach(model => console.log(`   - ${model}`));

  // Test text generation
  console.log('\nğŸ§ª Testing text generation...');
  try {
    const response = await ollama.generateResponse(
      'What is artificial intelligence?',
      'AI is a field of computer science that focuses on creating intelligent machines.'
    );
    console.log('âœ… Text generation working');
    console.log(`   Sample response: ${response.substring(0, 100)}...`);
  } catch (error) {
    console.error('âŒ Text generation failed:', error);
  }

  // Test embedding
  console.log('\nğŸ”¢ Testing embedding generation...');
  try {
    const response = await fetch('http://localhost:11434/api/embeddings', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'llama2',
        prompt: 'Test embedding',
      }),
    });

    if (response.ok) {
      const data = await response.json();
      console.log('âœ… Embedding generation working');
      console.log(`   Vector size: ${data.embedding.length}`);
    } else {
      console.log('âŒ Embedding generation failed');
    }
  } catch (error) {
    console.error('âŒ Embedding test failed:', error);
  }

  console.log('\nğŸ‰ Ollama setup complete!');
  console.log('\nNext steps:');
  console.log('1. Run: npm run sync-notion-test (to test full sync)');
  console.log('2. Run: npm run start-bot (to start Telegram bot)');
}

main().catch(console.error); 